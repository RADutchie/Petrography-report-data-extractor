{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bittesseractocrconda98f725dae0474fddbdf9b8103e3233bc",
   "display_name": "Python 3.7.5 64-bit ('tesseractOCR': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\nScript to extract text data from Mason petrology reports for load into SA_geodata. Input file path to the pdf \\ndocuments and it will return an excel speadsheet containing the report no, sample no and description.\\n'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script to extract text data from Mason petrology reports for load into SA_geodata. Input file path to the pdf \n",
    "documents and it will return an excel speadsheet containing the report no, sample no and description.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "import tempfile\n",
    "import shutil\n",
    "import re\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "from timeit import default_timer as timer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['D:\\\\Python ML\\\\Mason-petrography-extractor\\\\Mason_reports\\\\test\\\\MG4188.pdf', 'D:\\\\Python ML\\\\Mason-petrography-extractor\\\\Mason_reports\\\\test\\\\MG4196.pdf', 'D:\\\\Python ML\\\\Mason-petrography-extractor\\\\Mason_reports\\\\test\\\\MG4224.pdf']\n"
    }
   ],
   "source": [
    "#pdf_path = os.path.normpath(str(input(f'Please input the full path to the pdf files:')))\n",
    "pdf_path = os.path.normpath('D:\\\\Python ML\\\\Mason-petrography-extractor\\\\Mason_reports\\\\test')\n",
    "\n",
    "pdf_list = []\n",
    "with os.scandir(pdf_path) as it:\n",
    "    for entry in it:\n",
    "        if entry.name.endswith(\".pdf\") and entry.is_file():\n",
    "            pdf_list.append(entry.path)\n",
    "\n",
    "print(pdf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "working on MG4188.pdf\nlengths are equal :True\nworking on MG4196.pdf\nlengths are equal :True\nworking on MG4224.pdf\nlengths are equal :True\n"
    }
   ],
   "source": [
    "\n",
    "start = timer()\n",
    "\n",
    "\n",
    "report_dict = {'Report_No':[], 'Sample_No':[], 'Description':[]}\n",
    "rock_type_dict = {'Sample_No':[], 'Rock_Type':[]}\n",
    "\n",
    "# config for TesseractOCR\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    "\n",
    "#create a temp directory and Convert pdf pages to individual jpg images for OCR and image extraction\n",
    "\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "f_name = ''\n",
    "\n",
    "\n",
    "for pdf in pdf_list:\n",
    "    jpg_path_list = []\n",
    "    OCR_text_lst = []\n",
    "    f_name = pdf.split('\\\\')[-1]\n",
    "    images = convert_from_path(pdf, dpi = 300, output_folder=temp_dir.name,fmt='jpg')\n",
    "    \n",
    "# close PIL image objects\n",
    "    for im in images:\n",
    "        im.close()\n",
    "\n",
    "    print(f'working on {f_name}')\n",
    "\n",
    "#scan a file directory and return a list of jpg files to iterate over\n",
    "    with os.scandir(temp_dir.name) as it:\n",
    "        for entry in it:\n",
    "            if entry.name.endswith(\".jpg\") and entry.is_file():\n",
    "                jpg_path_list.append(entry.path)\n",
    "\n",
    "    for im_path in jpg_path_list:\n",
    "        image = cv2.imread(im_path, 0)\n",
    "        d = pytesseract.image_to_string(image, config=custom_config)\n",
    "        OCR_text_lst.append(d)\n",
    "\n",
    "    #Grab the footer text from page 2 of pdf\n",
    "    footer = OCR_text_lst[1].split('\\n')\n",
    "    footer[-1]\n",
    "\n",
    "    #generate the regex pattern to remove the footer from pages\n",
    "    start = footer[-1].split()[0] +' '+ footer[-1].split()[1]\n",
    "    end = footer[-1].split()[-2] +' '+ footer[-1].split()[-1]\n",
    "    footer_pattern = (f'{start}(.*?){end}')\n",
    "    \n",
    "    #generate a single string from the list of strings \n",
    "    text_string = ''\n",
    "    raw_text = text_string.join(OCR_text_lst)\n",
    "    raw_text\n",
    "\n",
    "    #find and replace footer with white space\n",
    "    text_c1 = re.sub(footer_pattern,'',raw_text)\n",
    "    \n",
    "    #Find the idx of the first instance of 'SAMPLE' used as a sample page headder, to  remove preceeding intro pages\n",
    "    petro = text_c1.find('PETROGRAPHIC')\n",
    "    first_sample = text_c1[petro:].find('SAMPLE') + petro\n",
    "    \n",
    "    # new string only contining the samples and removing all multiple newlines but adding extra newline at section headdings, then splitting into individual samples\n",
    "    \n",
    "    text_c2 = re.sub(r\"\\n+\", \"\\n\", text_c1[first_sample:])\n",
    "    text_c2 = re.sub(r\"(?<=\\w)\\.\\n(?=\\w)\",\".\\n\\n\", text_c2)\n",
    "    #text_c2 = re.sub(r\"(?<=\\w)\\n(?=\\w)\",\" \", text_c2,) #This will grab \\n in text and replace w wht space but messes with mineral lists\n",
    "\n",
    "    text_c2 = text_c2.replace('SAMPLE','***SAMPLE').replace('HOLE','\\nHOLE').replace('LITH','\\nLITH').replace('COMMENT','\\nCOMMENT').replace('SECTION','\\nSECTION').replace('HAND','\\nHAND').replace('FIG','\\nFIG').replace('ROCK','\\nROCK').replace('PETROGRAPHY','\\nPETROGRAPHY').replace('Mineral','\\nMineral').replace('In thin section','\\nIn thin section').replace('INTERPRETATION','\\nINTERPRETATION').replace('SOURCE','\\nSOURCE').replace('OTHER','\\nOTHER').replace('STRAT/\\nLITH', '\\nSTRAT/LITH').replace('APPENDIX','\\nAPPENDIX').replace('BRIEF','\\nBRIEF').replace('In polished thin','\\nIn polished thin').replace('CLIENT','\\nCLIENT').replace('FIELD','\\nFIELD').replace('GA NO','\\nGA NO').split('***')\n",
    "\n",
    "   #remove empty strings from list\n",
    "    descriptions = [x for x in text_c2 if x]\n",
    "    \n",
    "    fig_pattern = '(FIG|Fig)'\n",
    "    sample_no_list =[]\n",
    "    sample_no_pattern = '(\\d{7})|(R\\d{7})'\n",
    "    fig_list = []\n",
    "    rock_pattern = r\"(?s)ROCK N.*?:(.*?)PETRO\"\n",
    "    rock_list = []\n",
    "    for l in descriptions:\n",
    "        m = re.search(sample_no_pattern,l)\n",
    "        f = re.search(fig_pattern,l)\n",
    "        roc = re.search(rock_pattern,l,)\n",
    "        if m:\n",
    "            sample_no_list.append(m.group().strip('R'))\n",
    "        if f:\n",
    "            fig_list.append(m.group().strip('R'))\n",
    "        if roc:\n",
    "            rock_list.append(roc.group(1))\n",
    "\n",
    "    print(f'lengths are equal :{len(descriptions) == len(sample_no_list)}')\n",
    "\n",
    "    report_list = []\n",
    "    for i in range(len(descriptions)):\n",
    "        report_list.append(f_name)\n",
    "\n",
    "    report_dict['Report_No'].append(report_list)\n",
    "    report_dict['Sample_No'].append(sample_no_list)\n",
    "    report_dict['Description'].append(descriptions)\n",
    "    rock_type_dict['Sample_No'].append(sample_no_list)\n",
    "    rock_type_dict['Rock_Type'].append(rock_list)\n",
    "\n",
    "    #remove images from previous loop\n",
    "    with os.scandir(temp_dir.name) as it:\n",
    "        for entry in it:\n",
    "            if entry.name.endswith(\".jpg\") and entry.is_file():\n",
    "                os.remove(entry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(text_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[['MG4188.pdf', 32, 32, 32, 32, 32],\n ['MG4196.pdf', 4, 4, 4, 4, 4],\n ['MG4224.pdf', 67, 67, 67, 67, 67]]"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Cell to verify all reports have correct number of samples and descriptions, if not they can be dropped from export\n",
    "length_chek = []\n",
    "index_list =[]\n",
    "for i, (a,b,c,l,k) in enumerate(zip(report_dict['Report_No'],report_dict['Sample_No'],report_dict['Description'],rock_type_dict['Sample_No'],rock_type_dict['Rock_Type'])):\n",
    "    length_chek.append([a[0],len(a),len(b),len(c),len(l),len(k)])\n",
    "    if len(b)!=len(c) or len(l)!=len(k):\n",
    "        index_list.append(i)\n",
    "\n",
    "\n",
    "length_chek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[]"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                           Report_No  \\\n0  [MG4188.pdf, MG4188.pdf, MG4188.pdf, MG4188.pd...   \n1   [MG4196.pdf, MG4196.pdf, MG4196.pdf, MG4196.pdf]   \n2  [MG4224.pdf, MG4224.pdf, MG4224.pdf, MG4224.pd...   \n\n                                           Sample_No  \\\n0  [2137948, 2137949, 2137987, 2138095, 2138096, ...   \n1               [1588243, 1588242, 1588240, 1588241]   \n2  [2427063, 2427064, 2427070, 2427072, 2427074, ...   \n\n                                         Description  \n0  [SAMPLE ID : R2137948 (Wudinna region, South A...  \n1  [SAMPLE R# : R1588243 (Barossa Complex, South ...  \n2  [SAMPLE : 2427063 (Coompana Drilling Project, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Report_No</th>\n      <th>Sample_No</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[MG4188.pdf, MG4188.pdf, MG4188.pdf, MG4188.pd...</td>\n      <td>[2137948, 2137949, 2137987, 2138095, 2138096, ...</td>\n      <td>[SAMPLE ID : R2137948 (Wudinna region, South A...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[MG4196.pdf, MG4196.pdf, MG4196.pdf, MG4196.pdf]</td>\n      <td>[1588243, 1588242, 1588240, 1588241]</td>\n      <td>[SAMPLE R# : R1588243 (Barossa Complex, South ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[MG4224.pdf, MG4224.pdf, MG4224.pdf, MG4224.pd...</td>\n      <td>[2427063, 2427064, 2427070, 2427072, 2427074, ...</td>\n      <td>[SAMPLE : 2427063 (Coompana Drilling Project, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df_all = pd.DataFrame(report_dict)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failed = df_all.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "C:\\Users\\dutchr01\\AppData\\Local\\Continuum\\anaconda3\\envs\\tesseractOCR\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n  after removing the cwd from sys.path.\n"
    }
   ],
   "source": [
    "# create dataframe and export to excel\n",
    "df = pd.DataFrame(report_dict).drop(index_list).apply(pd.Series.explode)\n",
    "\n",
    "df2 = pd.Series(fig_list)\n",
    "\n",
    "df_failed = df_all.loc[index_list]\n",
    "\n",
    "df_rock = pd.DataFrame(rock_type_dict).drop(index_list).apply(pd.Series.explode)\n",
    "\n",
    "now = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "with pd.ExcelWriter(pdf_path+'\\\\'+now+'_Mason_petrology_export.xlsx') as writer:\n",
    "    df.to_excel(writer, sheet_name = 'extracted_pet_descriptions', index=False)\n",
    "    df_failed.to_excel(writer, sheet_name = 'Failed_extract', index=False)\n",
    "    df2.to_excel(writer, sheet_name='Samples with figs', index=False)\n",
    "\n",
    "with pd.ExcelWriter(pdf_path+'\\\\'+now+'_Rock_types.xlsx') as writer:\n",
    "    df_rock.to_excel(writer, sheet_name = 'Mason_rock_types', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[]"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "fig_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}