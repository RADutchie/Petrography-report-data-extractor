{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bittesseractocrconda98f725dae0474fddbdf9b8103e3233bc",
   "display_name": "Python 3.7.5 64-bit ('tesseractOCR': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# A python script that takes a directory continging Mason Petrology reports as pdf's and uses TesseractOCR and openCV to automatically extract the sample numbers, minerals and mineral modes for loading into SA_Geodata\n",
    "\n",
    "Where the mineralogical data is located in a seperate boxed table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "import tempfile\n",
    "import shutil\n",
    "import re\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "from timeit import default_timer as timer\n",
    "import json\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "#scan a file directory and return a list of pdf files to iterate over\n",
    "\n",
    "#pdf_path = os.path.normpath(str(input(f'Please input the full path to the pdf files:')))\n",
    "pdf_path = 'D:\\\\Python ML\\\\Mason-petrography-extractor\\\\Mason_reports\\\\test'\n",
    "\n",
    "\n",
    "pdf_list = []\n",
    "with os.scandir(pdf_path) as it:\n",
    "    for entry in it:\n",
    "        if entry.name.endswith(\".pdf\") and entry.is_file():\n",
    "            pdf_list.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['D:\\\\Python ML\\\\Mason-petrography-extractor\\\\Mason_reports\\\\test\\\\2525.pdf']\n"
    }
   ],
   "source": [
    "\n",
    "print(pdf_list)  # Print statement for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a temp directory and Convert pdf pages to individual jpg images for OCR and image extraction\n",
    "jpg_path_list = []\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "for pdf in pdf_list:\n",
    "    images = convert_from_path(pdf, dpi = 300, output_folder=temp_dir.name,fmt='jpg')\n",
    "    \n",
    "# close PIL image objects\n",
    "for im in images:\n",
    "    im.close()\n",
    "\n",
    "#scan a file directory and return a list of jpg files to iterate over\n",
    "#with os.scandir(temp_dir.name) as it:\n",
    "    #for entry in it:\n",
    "        #if entry.name.endswith(\".jpg\") and entry.is_file():\n",
    "            #jpg_path_list.append(entry.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# func to detect vertical and horizontal lines from image\n",
    "def lines(im, x=50): # x number between 1 and 255 (default 50)\n",
    "    # Defining a kernel length\n",
    "    global horizontal_lines_img, verticle_lines_img, kernel\n",
    "    kernel_length = np.array(im).shape[1]//x\n",
    "\n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    # Morphological operation to detect vertical lines from an image\n",
    "    img_temp1 = cv2.erode(binary_image, verticle_kernel, iterations=3)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "    #cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    img_temp2 = cv2.erode(binary_image, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "\n",
    "#func to sort the found contours\n",
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    "\n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "\n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "        key=lambda b:b[1][i], reverse=reverse))\n",
    "\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(jpg_path_list)  #print statement for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "C:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-01.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-02.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-03.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-04.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-05.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-06.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-07.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-08.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-09.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-10.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-11.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-12.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-13.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-14.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-15.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-16.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-17.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-18.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-19.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-20.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-21.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-22.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-23.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-24.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-25.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-26.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-27.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-28.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-29.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-30.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-31.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-32.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-33.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-34.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-35.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-36.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-37.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-38.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-39.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-40.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-41.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-42.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-43.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-44.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-45.jpg\nC:\\Temp\\tmp2vqp11_e\\ae145e98-45b2-48ce-a0b1-93d1a453b617-46.jpg\n"
    }
   ],
   "source": [
    "with os.scandir(temp_dir.name) as it:\n",
    "    for idx,im_path in enumerate(it):\n",
    "        print(im_path.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config for TesseractOCR\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    "\n",
    "mins_dict = {'R_No':[],'Mineral':[],'Vol %':[]}\n",
    "\n",
    "#RegEx patterns for sample nos and volume% charachters\n",
    "sample_no_pattern = '^(\\d{7})$|^(R\\d{7})$'\n",
    "Vol_pattern ='^((Tr)|(<1)|[\\d]|\\d{2})$' \n",
    "\n",
    "# for loop that iterates over jpg files in temp file, opens image and runs TesseractOCR on them\n",
    "with os.scandir(temp_dir.name) as it:\n",
    "    for idx,im_path in enumerate(it):\n",
    "        if im_path.name.endswith(\".jpg\") and im_path.is_file():\n",
    "            image = cv2.imread(im_path.path, 0)\n",
    "            d = pytesseract.image_to_data(image, config=custom_config,output_type=Output.DICT)\n",
    "            n_boxes = len(d['text'])\n",
    "            \n",
    "            # nested for loop that selects images that have the first line/first word == to 'SAMPLE'\n",
    "            for i in range(n_boxes):\n",
    "                if int(d['line_num'][i]) == 1 and int(d['word_num'][i]) == 1 and d['text'][i] =='SAMPLE':  \n",
    "                                \n",
    "                    #nested for loop to use regex to grab the sample number from the line 1 of the selected jpg pages\n",
    "                    for i in range(n_boxes):\n",
    "                        if int(d['line_num'][i]) == 1:  \n",
    "                            if re.match(sample_no_pattern, d['text'][i]):\n",
    "                                sample_no = (d['text'][i]).strip('R')\n",
    "                                #sample_nos.append(d['text'][i])\n",
    "\n",
    "                    ### section to find boxed mineralogy part of image \n",
    "                    thresh, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "                    #call lines function to find lines in image\n",
    "                    lines(image,50)\n",
    "\n",
    "                    # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "                    alpha = 0.5\n",
    "                    beta = 1.0 - alpha\n",
    "                    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "                    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "                    img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "                    (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "                    # Find contours for image, which will detect all the boxes\n",
    "                    contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                    # Sort all the contours by top to bottom.\n",
    "                    (contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")\n",
    "\n",
    "                    for c in contours:\n",
    "                        # Returns the location and width,height for every contour\n",
    "                        x, y, w, h = cv2.boundingRect(c)\n",
    "                        new_img = image[y:y+h,x:x+w]\n",
    "                    \n",
    "                    text = pytesseract.image_to_data(new_img,  config=custom_config, output_type=Output.DICT)\n",
    "\n",
    "                    x_boxes = len(text['text'])\n",
    "\n",
    "                    mins_lst = []\n",
    "                    vol_lst = []\n",
    "                    sample_lst = []\n",
    "                    \n",
    "                    for i in range(x_boxes):\n",
    "                        #if int(text['conf'][i]) > 30:\n",
    "                        # if int(text['line_num'][i]) > 1:\n",
    "                        if int(text['word_num'][i])==1 and not text['text'][i] == 'Mineral':\n",
    "                            mins_lst.append((text['text'][i]))\n",
    "\n",
    "                                #if int(text['word_num'][i])==1:\n",
    "                                    \n",
    "\n",
    "                    for i in range(x_boxes):\n",
    "                        #if int(text['conf'][i]) > 30:\n",
    "                            #if int(text['line_num'][i]) > 1:\n",
    "                        if int(text['left'][i]) < 1250:\n",
    "                            if re.match(Vol_pattern, text['text'][i]):\n",
    "                                vol_lst.append((text['text'][i]))\n",
    "\n",
    "                    for i in range(len(mins_lst)):\n",
    "                        sample_lst.append(sample_no)\n",
    "\n",
    "                    mins_dict['Mineral'].append(mins_lst)\n",
    "                    mins_dict['Vol %'].append(vol_lst)\n",
    "                    mins_dict['R_No'].append(sample_lst)\n",
    "\n",
    "                \n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove temp directory\n",
    "shutil.rmtree(temp_dir.name)\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "It took 2.7671521783333293 minutes to process a total of:\n22 samples\nWith 22 mineral lists\nAnd 22 volume lists\n"
    }
   ],
   "source": [
    "# print statments to indicate all pages OCR'd successfully\n",
    "Number_samples = len(mins_dict['R_No'])\n",
    "No_min_lists = len(mins_dict['Mineral'])\n",
    "No_vol_lists = len(mins_dict['Vol %'])\n",
    "print(f'It took {(end-start)/60} minutes to process a total of:')\n",
    "print(f'{Number_samples} samples')\n",
    "print(f'With {No_min_lists} mineral lists')\n",
    "print(f'And {No_vol_lists} volume lists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a pandas df of the mins_dict of sample lists\n",
    "df = pd.DataFrame(mins_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select completed records and explode the lists to individual values and select falied records for out put\n",
    "\n",
    "df_complete = df[df['Mineral'].str.len() == df['Vol %'].str.len()].apply(pd.Series.explode)\n",
    "df_failed = df[df['Mineral'].str.len() != df['Vol %'].str.len()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load mineral code mapping dict\n",
    "min_dict = json.load(open(Path(r'D:\\Python ML\\Mason-petrography-extractor\\notebooks\\min_dict.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo strip R's from sample no column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Vol % column from str to int and replace str values (like Tr or <1) to 0\n",
    "df_complete['mode'] = pd.to_numeric(df_complete['Vol %'],errors = 'coerce').replace(np.nan, 0, regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new col and populate with SA_Geo min abndance codes based on conditional args from the converted Vol %s\n",
    "df_complete['SA_Geo_mode'] = str(np.nan)\n",
    "df_complete.loc[df_complete['mode']==0,'SA_Geo_mode'] = 'RARE'\n",
    "df_complete.loc[df_complete['mode'] >= 70,'SA_Geo_mode'] = 'ABUNDANT'\n",
    "df_complete.loc[(df_complete['mode'] >= 30) & (df_complete['mode'] < 70),'SA_Geo_mode'] = 'MAJOR'\n",
    "df_complete.loc[(df_complete['mode'] >= 5) & (df_complete['mode'] < 30),'SA_Geo_mode'] = 'MINOR'\n",
    "df_complete.loc[(df_complete['mode'] > 0) & (df_complete['mode'] < 5),'SA_Geo_mode'] = 'TRACE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   R_No Mineral Vol %  mode SA_Geo_mode  check\n0   NaN     NaN   NaN     0        RARE  False\n1   NaN     NaN   NaN     0        RARE  False\n2   NaN     NaN   NaN     0        RARE  False\n3   NaN     NaN   NaN     0        RARE  False\n4   NaN     NaN   NaN     0        RARE  False\n5   NaN     NaN   NaN     0        RARE  False\n6   NaN     NaN   NaN     0        RARE  False\n7   NaN     NaN   NaN     0        RARE  False\n8   NaN     NaN   NaN     0        RARE  False\n9   NaN     NaN   NaN     0        RARE  False\n10  NaN     NaN   NaN     0        RARE  False\n11  NaN     NaN   NaN     0        RARE  False\n12  NaN     NaN   NaN     0        RARE  False\n13  NaN     NaN   NaN     0        RARE  False\n14  NaN     NaN   NaN     0        RARE  False\n15  NaN     NaN   NaN     0        RARE  False\n16  NaN     NaN   NaN     0        RARE  False\n17  NaN     NaN   NaN     0        RARE  False\n18  NaN     NaN   NaN     0        RARE  False\n19  NaN     NaN   NaN     0        RARE  False\n20  NaN     NaN   NaN     0        RARE  False\n21  NaN     NaN   NaN     0        RARE  False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>R_No</th>\n      <th>Mineral</th>\n      <th>Vol %</th>\n      <th>mode</th>\n      <th>SA_Geo_mode</th>\n      <th>check</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Run a check that the Mins in the Mineral col are in the mineral map JSON dict keys and output a missing_mins df for missing keys\n",
    "df_complete['check']=df_complete['Mineral'].str.strip('/?, ').isin(min_dict.keys())\n",
    "missing_mins = df_complete[df_complete['check']==False]\n",
    "missing_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   R_No Mineral Vol %  mode SA_Geo_mode  check SA_geo_min\n3   NaN     NaN   NaN     0        RARE  False        UKN\n20  NaN     NaN   NaN     0        RARE  False        UKN\n10  NaN     NaN   NaN     0        RARE  False        UKN\n13  NaN     NaN   NaN     0        RARE  False        UKN\n9   NaN     NaN   NaN     0        RARE  False        UKN\n15  NaN     NaN   NaN     0        RARE  False        UKN\n5   NaN     NaN   NaN     0        RARE  False        UKN\n21  NaN     NaN   NaN     0        RARE  False        UKN\n1   NaN     NaN   NaN     0        RARE  False        UKN\n8   NaN     NaN   NaN     0        RARE  False        UKN\n14  NaN     NaN   NaN     0        RARE  False        UKN\n11  NaN     NaN   NaN     0        RARE  False        UKN\n7   NaN     NaN   NaN     0        RARE  False        UKN\n2   NaN     NaN   NaN     0        RARE  False        UKN\n18  NaN     NaN   NaN     0        RARE  False        UKN\n17  NaN     NaN   NaN     0        RARE  False        UKN\n4   NaN     NaN   NaN     0        RARE  False        UKN\n19  NaN     NaN   NaN     0        RARE  False        UKN\n0   NaN     NaN   NaN     0        RARE  False        UKN\n16  NaN     NaN   NaN     0        RARE  False        UKN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>R_No</th>\n      <th>Mineral</th>\n      <th>Vol %</th>\n      <th>mode</th>\n      <th>SA_Geo_mode</th>\n      <th>check</th>\n      <th>SA_geo_min</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>RARE</td>\n      <td>False</td>\n      <td>UKN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Create a new Col and populate with the mapped SA_Geo min codes, replacing Mins not found in the mineral map JSON dict with the 'UKN' mineral code\n",
    "df_complete['SA_geo_min'] = str(np.nan)\n",
    "df_complete['SA_geo_min'] = df_complete['Mineral'].map(min_dict).replace([np.nan],['UKN'])\n",
    "df_complete.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output final tables to Excel\n",
    "now = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "SA_geo_mineralogy = df_complete[['R_No','Mineral','Vol %','SA_geo_min','SA_Geo_mode']]\n",
    "\n",
    "with pd.ExcelWriter(pdf_path+'\\\\'+now+'_SA_geodata_mineralogy.xlsx') as writer:\n",
    "    SA_geo_mineralogy.to_excel(writer, sheet_name = 'mapped_mineralogy', index=False)\n",
    "    df_failed.to_excel(writer, sheet_name = 'failed samples', index=False)\n",
    "    missing_mins.to_excel(writer, sheet_name = 'missing_minerals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}